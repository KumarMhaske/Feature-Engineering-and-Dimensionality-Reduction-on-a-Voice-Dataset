# Feature-Engineering-and-Dimensionality-Reduction-on-a-Voice-Dataset
In this project, I worked on a voice dataset to explore the power of feature engineering and dimensionality reduction in enhancing machine learning models' performance. üß†

#üîç Key Highlights:

Feature Engineering: Extracted critical features to better represent the data, paving the way for more accurate models.
Dimensionality Reduction with LDA: Applied Linear Discriminant Analysis (LDA) to reduce the dataset's dimensionality, significantly improving model accuracy and efficiency.
Machine Learning Models: Evaluated multiple models, including Logistic Regression, Decision Tree, Random Forest, SVC, and Naive Bayes.

#Notebook Overview:

Dataset: The notebook works with a voice dataset, likely aiming to perform binary classification tasks.

Feature Engineering: It includes steps for extracting relevant features to enhance model performance.

Dimensionality Reduction: Linear Discriminant Analysis (LDA) is applied to reduce the dataset's dimensionality, improving both accuracy and efficiency.

#Machine Learning Models:

Logistic Regression with LDA achieved around 97% accuracy.
Decision Tree also showed 97% accuracy with LDA.
Random Forest reached 94% accuracy post-LDA.
Support Vector Classifier (SVC) improved to 97% accuracy with LDA.
Naive Bayes performed well with a 97% accuracy after LDA.

#Comparative Analysis: The notebook compares the models' accuracy scores before and after applying LDA.

#üìä Results:
After applying LDA, most models, including Logistic Regression, SVC, and Naive Bayes, achieved an impressive accuracy of 97%! The project demonstrated how dimensionality reduction could optimize model performance.

#MachineLearning #DataScience #FeatureEngineering #DimensionalityReduction #Python #LogisticRegression #DecisionTree #RandomForest #SupportVectorMachine #NaiveBayes #DataAnalysis #AI
